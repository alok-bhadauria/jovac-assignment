1. What are the assumptions of linear regression?
Linear regression assumes a straight-line link between inputs and output. 
Errors should be evenly spread, data points independent, and the errors roughly normal. 
Also, features shouldn’t be too closely related to each other.

2. When should you use logistic regression instead of linear regression?
We use logistic regression when we are predicting categories, like YES or NO. 
It’s built for classification and gives probabilities, while linear regression predicts continuous numbers.

3. What is the interpretation of coefficients in logistic regression?
Each coefficient shows how the odds change when that feature increases by one, with others held constant. 
The exponent of the coefficient tells you how much the odds multiply.

4. What is the difference between sigmoid and softmax functions?
Sigmoid gives a value between 0 and 1, so it’s good for binary classification. 
Softmax spreads the output across multiple classes, so it’s used when we have more than two.

5. Why is R-squared not suitable for evaluating logistic regression models?
R-squared fits regression, not classification. 
Logistic regression is about predicting categories, so metrics like accuracy or AUC work better.